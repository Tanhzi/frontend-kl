import React, { useEffect, useState, useRef } from 'react';
import { useNavigate, useLocation } from 'react-router-dom';
import './Photo.css';
import Chatbot from '../../components/Chatbot';
import { useCountdown } from "../../contexts/CountdownContext";

function Photo() {
  // --- 1. CONFIG & STATE ---
  const getAuth = () => {
    const saved = localStorage.getItem('auth');
    return saved ? JSON.parse(saved) : null;
  };

  const [auth] = useState(getAuth());
  const { id_admin } = auth || {};

  const [countdown2, setCountdown] = useState(5);
  const [photoIndex, setPhotoIndex] = useState(1);
  const [photos, setPhotos] = useState([]); // L∆∞u d·∫°ng Blob URL ƒë·ªÉ nh·∫π DOM
  const [flash, setFlash] = useState(false);
  const [isMirror, setIsMirror] = useState(false); // Mirror preview
  
  // Settings th·ªùi gian
  const [initialTime, setInitialTime] = useState(5);
  const [subsequentTime, setSubsequentTime] = useState(8);
  
  const [isStarted, setIsStarted] = useState(true);
  const [maxPhotos, setMaxPhotos] = useState(8);
  const [isRetaking, setIsRetaking] = useState(false);
  const [retakeIndex, setRetakeIndex] = useState(null);
  
  // State ph·ª•c v·ª• Retake
  const [currentPhotosState, setCurrentPhotosState] = useState([]);
  const [currentSelectedSlotsState, setCurrentSelectedSlotsState] = useState([]);
  const [currentAppliedFiltersState, setCurrentAppliedFiltersState] = useState({});

  const [previewCrop, setPreviewCrop] = useState(null);
  const photosContainerRef = useRef(null);

  // Refs ph·∫ßn c·ª©ng
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const streamRef = useRef(null);
  const imageCaptureRef = useRef(null);

  const navigate = useNavigate();
  const location = useLocation();
  
  // L·∫•y d·ªØ li·ªáu t·ª´ trang tr∆∞·ªõc
  const {
    size, cut, selectedFrame, selectedFrameId, price,
    retakeIndex: incomingRetakeIndex,
    currentPhotos: incomingCurrentPhotos,
    currentSelectedSlots: incomingCurrentSelectedSlots,
    currentAppliedFilters: incomingCurrentAppliedFilters
  } = location.state || {};

  // --- 2. HELPER FUNCTIONS ---

  // Chuy·ªÉn Blob sang Base64 (D√πng khi c·∫ßn l∆∞u/g·ª≠i ƒëi)
  const blobToDataURL = (blob) =>
    new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result);
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });

  const getMaxPhotos = (cutValue) => {
    const cutNum = Number(cutValue);
    if (cutNum === 3) return 3;
    if (cutNum === 41 || cutNum === 42) return 4;
    if (cutNum === 6) return 6;
    return 8;
  };

  const { formattedCountdown, countdown } = useCountdown();

  // --- 3. EFFECTS: NAVIGATION & INIT ---

  useEffect(() => {
    if (countdown === 0) navigate('/Appclien');
  }, [countdown, navigate]);

  // Thi·∫øt l·∫≠p s·ªë l∆∞·ª£ng ·∫£nh v√† tr·∫°ng th√°i Retake
  useEffect(() => {
    if (incomingRetakeIndex !== undefined && incomingCurrentPhotos) {
      setIsRetaking(true);
      setRetakeIndex(incomingRetakeIndex);
      setCurrentPhotosState(incomingCurrentPhotos);
      setCurrentSelectedSlotsState(incomingCurrentSelectedSlots || []);
      setCurrentAppliedFiltersState(incomingCurrentAppliedFilters || {});
      setPhotos([]);
      setPhotoIndex(1);
      setMaxPhotos(1);
      setIsStarted(true);
    } else {
      setIsRetaking(false);
      setRetakeIndex(null);
      setCurrentPhotosState([]);
      setCurrentSelectedSlotsState([]);
      setCurrentAppliedFiltersState({});
      setMaxPhotos(getMaxPhotos(cut));
      setPhotos([]);
      setPhotoIndex(1);
      setIsStarted(false);
    }
  }, [incomingRetakeIndex, incomingCurrentPhotos, cut]);

  // L·∫•y c·∫•u h√¨nh t·ª´ Server (Time & Mirror)
  useEffect(() => {
    if (!id_admin) return;
    fetch(`${import.meta.env.VITE_API_BASE_URL}/camera/basic?id_admin=${id_admin}`)
      .then((res) => res.json())
      .then((data) => {
        if (!data) return;
        setInitialTime(Number(data.time1) || 5);
        setSubsequentTime(Number(data.time2) || 8);
        // L∆∞u √Ω: Mirror ·ªü ƒë√¢y ch·ªâ n√™n √°p d·ª•ng cho Preview (ng∆∞·ªùi d√πng nh√¨n th·∫•y).
        // ·∫¢nh ch·ª•p ra th∆∞·ªùng n√™n l√† ·∫£nh thu·∫≠n (kh√¥ng mirror) tr·ª´ khi kh√°ch y√™u c·∫ßu.
        setIsMirror(Number(data.mirror) === 1);
      })
      .catch((err) => console.error('L·ªói l·∫•y c·∫•u h√¨nh:', err));
  }, [id_admin]);

  // --- 4. CAMERA SETUP (OPTIMIZED) ---
  
  useEffect(() => {
    let mounted = true;

    const setupCamera = async () => {
      try {
        // ∆Øu ti√™n 4K -> 2K -> FHD
        const constraints = {
          audio: false,
          video: {
            facingMode: 'user',
            width: { ideal: 3840 },
            height: { ideal: 2160 },
            frameRate: { ideal: 30 },
          },
        };

        let stream = await navigator.mediaDevices.getUserMedia(constraints);
        if (!mounted) return;
        streamRef.current = stream;

        // C·∫•u h√¨nh ImageCapture v√† Advanced Settings
        const track = stream.getVideoTracks()[0];
        if (track) {
          const settings = track.getSettings();
          console.log(`üì∏ Camera Active: ${settings.width}x${settings.height}`);
          
          if ('ImageCapture' in window) {
            imageCaptureRef.current = new window.ImageCapture(track);
          }

          // T·ªêI ∆ØU TH√äM: C·ªë g·∫Øng t·∫Øt t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh √°nh s√°ng n·∫øu b·ªã nh√°y
          // (Ch·ªâ ho·∫°t ƒë·ªông v·ªõi camera h·ªó tr·ª£)
          try {
            const capabilities = track.getCapabilities();
            const advancedConstraints = {};
            if (capabilities.whiteBalanceMode && capabilities.whiteBalanceMode.includes('continuous')) {
               advancedConstraints.whiteBalanceMode = 'continuous';
            }
            if (capabilities.exposureMode && capabilities.exposureMode.includes('continuous')) {
               advancedConstraints.exposureMode = 'continuous';
            }
            if (Object.keys(advancedConstraints).length > 0) {
              await track.applyConstraints({ advanced: [advancedConstraints] });
            }
          } catch (e) {
            console.warn('Kh√¥ng th·ªÉ set advanced constraints', e);
          }
        }

        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            videoRef.current.play().catch(e => console.log("Play error:", e));
            updatePreviewCrop();
          };
        }
      } catch (err) {
        console.error('L·ªói camera ch√≠nh, th·ª≠ fallback:', err);
        try {
          const fallbackStream = await navigator.mediaDevices.getUserMedia({ 
            video: { width: { ideal: 1920 }, height: { ideal: 1080 } } 
          });
          if (!mounted) return;
          streamRef.current = fallbackStream;
          if (videoRef.current) {
            videoRef.current.srcObject = fallbackStream;
            videoRef.current.play();
          }
        } catch (e2) {
          console.error('Kh√¥ng th·ªÉ m·ªü camera:', e2);
        }
      }
    };

    setupCamera();

    const cleanup = () => {
      mounted = false;
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((t) => t.stop());
      }
      imageCaptureRef.current = null;
    };

    window.addEventListener('beforeunload', cleanup);
    return () => {
      window.removeEventListener('beforeunload', cleanup);
      cleanup();
    };
  }, [cut]);

  // --- 5. CROP LOGIC ---

  const getCropDimensions = (cutValue, videoWidth, videoHeight) => {
    const cutNum = Number(cutValue);
    let targetAspectRatio = 1;

    switch (cutNum) {
      case 3: targetAspectRatio = 276 / 220; break;
      case 41: targetAspectRatio = 276 / 195; break;
      case 42: targetAspectRatio = 260 / 330; break;
      case 6: targetAspectRatio = 280 / 240; break;
      default: targetAspectRatio = 1;
    }

    const videoAR = videoWidth / videoHeight;
    let w, h, x, y;

    if (videoAR > targetAspectRatio) {
      h = videoHeight;
      w = Math.round(h * targetAspectRatio);
      x = Math.round((videoWidth - w) / 2);
      y = 0;
    } else {
      w = videoWidth;
      h = Math.round(w / targetAspectRatio);
      x = 0;
      y = Math.round((videoHeight - h) / 2);
    }
    return { cropWidth: w, cropHeight: h, cropX: x, cropY: y };
  };

  const updatePreviewCrop = () => {
    const video = videoRef.current;
    if (!video || !video.videoWidth) return;

    const { cropWidth, cropHeight, cropX, cropY } = getCropDimensions(cut, video.videoWidth, video.videoHeight);
    
    // T√≠nh to√°n hi·ªÉn th·ªã khung crop tr√™n m√†n h√¨nh (CSS calculation)
    // Gi·ªØ nguy√™n logic t√≠nh to√°n hi·ªÉn th·ªã c·ªßa b·∫°n ·ªü ƒë√¢y v√¨ n√≥ ph·ª• thu·ªôc v√†o CSS layout
    const containerW = window.innerWidth;
    const containerH = window.innerHeight;
    const videoAR = video.videoWidth / video.videoHeight;
    const containerAR = containerW / containerH;
    
    let displayW, displayH, offX, offY;
    
    if (videoAR > containerAR) {
        displayW = containerW;
        displayH = containerW / videoAR;
        offX = 0;
        offY = (containerH - displayH) / 2;
    } else {
        displayH = containerH;
        displayW = containerH * videoAR;
        offY = 0;
        offX = (containerW - displayW) / 2;
    }
    
    const scaleX = displayW / video.videoWidth;
    const scaleY = displayH / video.videoHeight;
    
    setPreviewCrop({
      x: offX + cropX * scaleX,
      y: offY + cropY * scaleY,
      width: cropWidth * scaleX,
      height: cropHeight * scaleY
    });
  };

  // --- 6. SHOOTING LOGIC ---

  // X·ª≠ l√Ω chuy·ªÉn trang sau khi ch·ª•p xong
  useEffect(() => {
    if (!isStarted) return;

    if (photoIndex > maxPhotos) {
      setTimeout(() => {
        // Logic ƒëi·ªÅu h∆∞·ªõng gi·ªØ nguy√™n nh∆∞ c≈©
        const finalPhotos = photos; // ·ªû ƒë√¢y photos l√† m·∫£ng dataUrl
        
        if (isRetaking) {
          const newPhoto = finalPhotos[0];
          const updatedPhotos = [...currentPhotosState];
          updatedPhotos[retakeIndex] = newPhoto;
          
          const updatedSlots = [...currentSelectedSlotsState];
          if (updatedSlots[retakeIndex]) {
            updatedSlots[retakeIndex] = { ...updatedSlots[retakeIndex], photo: newPhoto, flip: false };
          }
          
          const updatedFilters = { ...currentAppliedFiltersState };
          updatedFilters[retakeIndex] = 'original';

          navigate('/Selphoto', {
            state: {
              photos: updatedPhotos,
              selectedSlots: updatedSlots,
              appliedFilters: updatedFilters,
              size, cut, selectedFrame, selectedFrameId, price
            },
          });
        } else {
          const initialSlots = finalPhotos.map(p => ({ photo: p, flip: false }));
          const initialFilters = {};
          finalPhotos.forEach((_, i) => initialFilters[i] = 'original');
          
          navigate('/Selphoto', {
            state: {
              photos: finalPhotos,
              selectedSlots: initialSlots,
              appliedFilters: initialFilters,
              size, cut, selectedFrame, selectedFrameId, price
            },
          });
        }
      }, 1500);
      return;
    }

    // ƒê·∫øm ng∆∞·ª£c ch·ª•p
    const currentTime = photoIndex === 1 ? initialTime : subsequentTime;
    setCountdown(currentTime);
    const timer = setTimeout(() => handleTakePhoto(), currentTime * 1000);
    return () => clearTimeout(timer);
  }, [photoIndex, isStarted, maxPhotos, initialTime, subsequentTime, photos]); // Dependencies t·ªëi gi·∫£n

  // ƒê·∫øm ng∆∞·ª£c UI
  useEffect(() => {
    if (!isStarted || photoIndex > maxPhotos) return;
    const interval = setInterval(() => {
      setCountdown(p => (p > 0 ? p - 1 : 0));
    }, 1000);
    return () => clearInterval(interval);
  }, [isStarted, photoIndex, maxPhotos]);


  const handleTakePhoto = async () => {
    if (!videoRef.current || photoIndex > maxPhotos) return;

    const video = videoRef.current;
    const vW = video.videoWidth;
    const vH = video.videoHeight;

    if (!vW || !vH) return;

    const { cropWidth, cropHeight, cropX, cropY } = getCropDimensions(cut, vW, vH);
    
    const canvas = canvasRef.current;
    canvas.width = cropWidth;
    canvas.height = cropHeight;
    const ctx = canvas.getContext('2d');

    // T·ªëi ∆∞u ch·∫•t l∆∞·ª£ng v·∫Ω
    ctx.imageSmoothingEnabled = true;
    ctx.imageSmoothingQuality = 'high';

    ctx.clearRect(0, 0, cropWidth, cropHeight);
    ctx.save();

    // X·ª≠ l√Ω Mirror (L∆∞u √Ω: N·∫øu mu·ªën ·∫£nh in ra ƒë√∫ng chi·ªÅu ch·ªØ th√¨ KH√îNG n√™n mirror ·ªü ƒë√¢y, 
    // tr·ª´ khi isMirror th·ª±c s·ª± √°m ch·ªâ vi·ªác l·∫≠t ·∫£nh ƒë·∫ßu ra)
    if (isMirror) {
      ctx.translate(cropWidth, 0);
      ctx.scale(-1, 1);
    }

    try {
      // C√°ch 1: D√πng ImageCapture (Ch·∫•t l∆∞·ª£ng cao nh·∫•t)
      if (imageCaptureRef.current) {
        const blob = await imageCaptureRef.current.takePhoto();
        const imgBitmap = await createImageBitmap(blob); // Hi·ªáu nƒÉng t·ªët h∆°n new Image()
        
        const scaleX = imgBitmap.width / vW;
        const scaleY = imgBitmap.height / vH;

        ctx.drawImage(
          imgBitmap,
          cropX * scaleX, cropY * scaleY,
          cropWidth * scaleX, cropHeight * scaleY,
          0, 0,
          cropWidth, cropHeight
        );
        imgBitmap.close(); // Gi·∫£i ph√≥ng b·ªô nh·ªõ
      } 
      // C√°ch 2: Fallback ch·ª•p t·ª´ video feed
      else {
        ctx.drawImage(video, cropX, cropY, cropWidth, cropHeight, 0, 0, cropWidth, cropHeight);
      }
    } catch (err) {
      console.warn("L·ªói ch·ª•p ·∫£nh, fallback video:", err);
      ctx.drawImage(video, cropX, cropY, cropWidth, cropHeight, 0, 0, cropWidth, cropHeight);
    }
    
    ctx.restore();

    // Xu·∫•t ·∫£nh JPEG Quality 1.0 (T·ªët nh·∫•t)
    // N·∫øu mu·ªën nh·∫π h∆°n c√≥ th·ªÉ ƒë·ªÉ 0.95
    const dataUrl = canvas.toDataURL('image/jpeg', 1.0);
    
    // Play sound (n·∫øu c√≥ file √¢m thanh)
    // const audio = new Audio('/shutter.mp3'); audio.play();

    applyCapturedPhoto(dataUrl);
  };

  const applyCapturedPhoto = (dataUrl) => {
    setPhotos(prev => [...prev, dataUrl]);
    setPhotoIndex(prev => prev + 1);
    setFlash(true);
    setTimeout(() => setFlash(false), 150);
    
    // Auto scroll
    setTimeout(() => {
      photosContainerRef.current?.lastElementChild?.scrollIntoView({ behavior: 'smooth', block: 'end' });
    }, 50);
  };

  const handleScreenClick = () => {
    if (!isStarted) setIsStarted(true);
  };

  return (
    <div className="photo-container" onClick={handleScreenClick}>
      <video
        ref={videoRef}
        className={`video-stream-fullscreen ${isMirror ? 'video-mirror' : ''}`}
        playsInline muted autoPlay
      />
      
      <div className="countdown">‚åõ: {formattedCountdown}</div>
      <canvas ref={canvasRef} className="d-none" />

      {/* Mask Overlay */}
      {previewCrop && (
        <div className="crop-mask-overlay">
             {/* ... Gi·ªØ nguy√™n ph·∫ßn render mask c·ªßa b·∫°n ... */}
             {/* ƒê·ªÉ ng·∫Øn g·ªçn t√¥i kh√¥ng paste l·∫°i ph·∫ßn div mask-bar, d√πng l·∫°i logic c≈© l√† ·ªïn */}
             <div className="crop-outline"
                style={{
                  left: `${previewCrop.x}px`, top: `${previewCrop.y}px`,
                  width: `${previewCrop.width}px`, height: `${previewCrop.height}px`,
                  boxShadow: '0 0 0 9999px rgba(0, 0, 0, 0.6)'
                }}
             />
        </div>
      )}

      {flash && <div className="flash-overlay-fullscreen" />}

      {!isStarted && (
        <div className="camera-icon-overlay">
          <div className="camera-icon"><i className="fas fa-camera" /><p>Ch·∫°m m√†n h√¨nh ƒë·ªÉ b·∫Øt ƒë·∫ßu</p></div>
        </div>
      )}

      {isStarted && photoIndex <= maxPhotos && (
        <div className="countdown-center">
          <div className="countdown-number-large">{countdown2}</div>
        </div>
      )}

      <div className="photo-counter-top-right">
        {photoIndex <= maxPhotos ? `${photoIndex}/${maxPhotos}` : 'Ho√†n th√†nh!'}
      </div>

      {photos.length > 0 && (
        <div className="captured-photos-column" ref={photosContainerRef}>
          <div className="captured-photos-title">·∫¢nh ({photos.length}/{maxPhotos})</div>
          {photos.map((p, i) => (
            <img key={i} src={p} alt={`pic-${i}`} className="captured-photo-item" />
          ))}
        </div>
      )}
      <Chatbot />
    </div>
  );
}

export default Photo;